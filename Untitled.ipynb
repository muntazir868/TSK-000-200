{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02299565",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'object_detection'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mimageio\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatetime\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m datetime\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mobject_detection\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ops \u001b[38;5;28;01mas\u001b[39;00m utils_ops\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mobject_detection\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m label_map_util\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mobject_detection\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m visualization_utils \u001b[38;5;28;01mas\u001b[39;00m vis_util\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'object_detection'"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "import imageio\n",
    "from datetime import datetime\n",
    "from object_detection.utils import ops as utils_ops\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import visualization_utils as vis_util\n",
    "\n",
    "# patch tf1 into `utils.ops`\n",
    "utils_ops.tf = tf.compat.v1\n",
    "\n",
    "# Patch the location of gfile\n",
    "tf.gfile = tf.io.gfile\n",
    "\n",
    "RESEARCH_PATH = 'C:/Users/Alireza/Anaconda3/tensorflow_models/models/research'\n",
    "PATH_TO_LABELS = RESEARCH_PATH + '/object_detection/data/mscoco_label_map.pbtxt'\n",
    "\n",
    "\n",
    "def load_model(model_dir):\n",
    "    model = tf.saved_model.load(str(model_dir))\n",
    "    model = model.signatures['serving_default']\n",
    "    return model\n",
    "\n",
    "\n",
    "def run_inference_for_single_image(model, image):\n",
    "    # image = np.asarray(image)\n",
    "    # The input needs to be a tensor, convert it using `tf.convert_to_tensor`.\n",
    "    input_tensor = tf.convert_to_tensor(image)\n",
    "    # The model expects a batch of images, so add an axis with `tf.newaxis`.\n",
    "    input_tensor = input_tensor[tf.newaxis, ...]\n",
    "\n",
    "    # Run inference\n",
    "    output_dict = model(input_tensor)\n",
    "\n",
    "    # All outputs are batches tensors.\n",
    "    # Convert to numpy arrays, and take index [0] to remove the batch dimension.\n",
    "    # We're only interested in the first num_detections.\n",
    "    num_detections = int(output_dict.pop('num_detections'))\n",
    "    output_dict = {key: value[0, :num_detections].numpy()\n",
    "                   for key, value in output_dict.items()}\n",
    "    output_dict['num_detections'] = num_detections\n",
    "\n",
    "    # detection_classes should be ints.\n",
    "    output_dict['detection_classes'] = output_dict['detection_classes'].astype(np.int64)\n",
    "\n",
    "    # Handle models with masks:\n",
    "    if 'detection_masks' in output_dict:\n",
    "        # Reframe the the bbox mask to the image size.\n",
    "        detection_masks_reframed = utils_ops.reframe_box_masks_to_image_masks(\n",
    "            output_dict['detection_masks'], output_dict['detection_boxes'],\n",
    "            image.shape[0], image.shape[1])\n",
    "        detection_masks_reframed = tf.cast(detection_masks_reframed > 0.5,\n",
    "                                           tf.uint8)\n",
    "        output_dict['detection_masks_reframed'] = detection_masks_reframed.numpy()\n",
    "\n",
    "    return output_dict\n",
    "\n",
    "\n",
    "def show_inference(model, image_inp):\n",
    "    # the array based representation of the image will be used later in order to prepare the\n",
    "    # result image with boxes and labels on it.\n",
    "    # Actual detection.\n",
    "    output_dict = run_inference_for_single_image(model, image_inp)\n",
    "    # Visualization of the results of a detection.\n",
    "    vis_util.visualize_boxes_and_labels_on_image_array(\n",
    "        image_inp,\n",
    "        output_dict['detection_boxes'],\n",
    "        output_dict['detection_classes'],\n",
    "        output_dict['detection_scores'],\n",
    "        category_index,\n",
    "        instance_masks=output_dict.get('detection_masks_reframed', None),\n",
    "        use_normalized_coordinates=True,\n",
    "        line_thickness=8)\n",
    "\n",
    "    return image_inp\n",
    "\n",
    "\n",
    "def get_argument():\n",
    "    parser = argparse.ArgumentParser(\n",
    "        description='This Programme tries to detect objects in a picture or video'\n",
    "                    'Developer : S.Alireza Moazeni')\n",
    "\n",
    "    parser.add_argument('--content',\n",
    "                        help='image or video',\n",
    "                        default=\"video\")\n",
    "    parser.add_argument('--path',\n",
    "                        help='The path of content',\n",
    "                        default=\"./traffic.mp4\")\n",
    "    parser.add_argument('--model',\n",
    "                        help='which model do you want to use',\n",
    "                        default=\"ssd_mobilenet_v1_coco_2017_11_17\")\n",
    "\n",
    "    return parser.parse_args()\n",
    "\n",
    "\n",
    "def process_single_image(image_path, model):\n",
    "    image_np = show_inference(model, np.array(Image.open(image_path)))\n",
    "    image_np = Image.fromarray(image_np)\n",
    "    image_np.save(\"output.png\")\n",
    "    print(\"Output image is ready...\")\n",
    "\n",
    "\n",
    "def process_single_video(video_path, model):\n",
    "    video_reader = imageio.get_reader(video_path)\n",
    "    out_put_path = video_path[0:video_path.find('.', 1)] + '_annotated.mp4'\n",
    "    video_writer = imageio.get_writer(out_put_path, fps=10)\n",
    "\n",
    "    # loop through and process each frame\n",
    "    t0 = datetime.now()\n",
    "    n_frames = 0\n",
    "\n",
    "    for frame in video_reader:\n",
    "        # rename for convenience\n",
    "        image_np = frame\n",
    "        n_frames += 1\n",
    "\n",
    "        # Actual detection.\n",
    "        image_np = show_inference(model, image_np)\n",
    "\n",
    "        # instead of plotting image, we write the frame to video\n",
    "        video_writer.append_data(image_np)\n",
    "\n",
    "    fps = n_frames / (datetime.now() - t0).total_seconds()\n",
    "    print(\"Frames processed: %s, Speed: %s fps\" % (n_frames, fps))\n",
    "\n",
    "    # clean up\n",
    "    video_writer.close()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    args = get_argument()\n",
    "    category_index = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS, use_display_name=True)\n",
    "    PATH_TO_MODEL = RESEARCH_PATH + '/object_detection/' + args.model + '/saved_model'\n",
    "    detection_model = load_model(model_dir=PATH_TO_MODEL)\n",
    "\n",
    "    if args.content == 'image':\n",
    "        process_single_image(args.path, detection_model)\n",
    "    elif args.content == 'video':\n",
    "        process_single_video(args.path, detection_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005f67ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
